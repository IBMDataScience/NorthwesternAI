{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Bank Client's Financial Product subscription using Predictive Models.\n",
    "\n",
    "   - [IBM Data Science](https://github.com/IBMDataScience/NorthwesternAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "1. Intrdouction\n",
    "2. Dataset\n",
    "3. Data Understanding/Exploration\n",
    "4. Data Preparation\n",
    "5. Data Split\n",
    "6. Building a Model\n",
    "7. Model Evaluation\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "We will illustrates the Machine Learning classification using the Decision Tree. Decision Tree, is usually a better choice compare to the logistic regression and other techniques for explanatory purpose. We will use the real life data set which is highly imbalance i.e the number of positive sample is much less than the number of negative samples.\n",
    "\n",
    "We will walk the user to the the following conceptual steps\n",
    "\n",
    "-  Data Set Description.\n",
    "-  Exploratory Analysis to understand the data.\n",
    "-  Use various preprocessing to clean and prepare the data.\n",
    "-  Use Decision Tree to run the classification.\n",
    "-  Model Accuracy & Evaluation\n",
    "-  Conver the Model to PMML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set <a name=\"dataset\"></a>\n",
    "\n",
    "We will use the dataset from [UCI repository for Bank Marketing Data Set](http://archive.ics.uci.edu/ml/datasets/Bank+Marketing).\n",
    "\n",
    "The source of the dataset is \n",
    "\n",
    "[Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014\n",
    "\n",
    "\n",
    "## Data Set Infromation\n",
    "\n",
    "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. \n",
    "\n",
    "\n",
    "### Feature Information\n",
    "\n",
    "###### A. Bank Client Information\n",
    "| col num| feature name| feature description |\n",
    "|--------|:-----------:|:--------------------|\n",
    "|1|  **age** |(numeric)|\n",
    "|2|  **job** | type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')|\n",
    "|3| **marital**| marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)|\n",
    "|4| **education** |(categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')|\n",
    "|5| **default**| has credit in default? (categorical: 'no','yes','unknown')|\n",
    "|6| **balance**| how much credit card balance|\n",
    "|7| **housing**| has housing loan? (categorical: 'no','yes','unknown')|\n",
    "|8| **loan**| has personal loan? (categorical: 'no','yes','unknown')|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### B. Attributes related with the last contact of the current campaign\n",
    "\n",
    "| col num| feature name| feature description |\n",
    "|--------|:-----------:|:--------------------|\n",
    "|9|**contact**| contact communication type (categorical: 'cellular','telephone')| \n",
    "|10|**day**| last contact day of month (categorical: '1', '2', '3', ..., '30', '31')|\n",
    "|11|**month**| last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')|\n",
    "|12|**duration**|last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.|\n",
    "\n",
    "###### C. other attributes\n",
    "\n",
    "| col num| feature name| feature description |\n",
    "|--------|:-----------:|:--------------------|\n",
    "|13|**campaign**|number of contacts performed during this campaign and for this client (numeric, includes last contact)|\n",
    "|14|**pdays**|number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)|\n",
    "|15|**previous**|number of contacts performed before this campaign and for this client (numeric)|\n",
    "|16|**poutcome**|outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success') |\n",
    "\n",
    "\n",
    "\n",
    "###### E. Output variable (desired target) \n",
    "| col num| feature name| feature description |\n",
    "|--------|:-----------:|:--------------------|\n",
    "|17|**y**| has the client subscribed a term deposit? (binary: 'yes','no')|\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statement of the Classification Problem  <a name=\"pb_statement\"></a>\n",
    "\n",
    "Now we know the schema of the dataset, lets formalize our model building task.\n",
    "\n",
    "1) We will build a machine learning model to predict if a client is likely to subscribed to the a financial product i.e term deposit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Challenges in building ML model\n",
    "\n",
    "There are many challenges in the machine learning. A few common examples\n",
    "\n",
    "   * Non Representative data\n",
    "\n",
    "   * Insufficient data.\n",
    "\n",
    "   * Poor quality data.\n",
    "   \n",
    "   * Imbalance data set.\n",
    "\n",
    "   * Irrelevant features.\n",
    "\n",
    "   * Overfitting the model on data\n",
    "\n",
    "   * Underfitting of the model on data\n",
    "\n",
    "   * Whether model will generalize or not\n",
    "\n",
    "   We will explore many of them as we proceed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software and Tools (Scikit Learn) \n",
    "\n",
    "##### Python Package Dependencies\n",
    "\n",
    "We will use the [scikit learn package](http://scikit-learn.org/stable/documentation.html) for this task. Next few cells load the libraries needed for this notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pandas for \n",
    "##   1. reading various files into the dataframe\n",
    "##   2. to performa various data manipulation tasks\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#for deicison tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "# for preprocessing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# for custom transformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# for creating pipeline\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "# for various metrics and reporting\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load matplot lib for various plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"font\", size=14)\n",
    "\n",
    "# we will use the seaborn for visually appealing plots\n",
    "import seaborn as sns\n",
    "sns.set() # set the seaborn stylesheet\n",
    "#sns.set(style=\"white\")\n",
    "#sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration <a name=\"data_exploration\"></a>\n",
    "\n",
    "\n",
    "First step to build predictive model, is to explore data set so that one can get as much insight as possible so that we can do better feature engineering.\n",
    "\n",
    "##### Data Set loading \n",
    "\n",
    "We will use [pandas](https://pandas.pydata.org/) to read data and create dataframe. \n",
    "   \n",
    "   * Pandas support a lot more functionalities for analysis than reading and writing the dataframe. We will use a few of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv file\n",
    "import sys\n",
    "import types\n",
    "import pip\n",
    "\n",
    "\n",
    "# if you are using notebook on your laptop. use following to load\n",
    "#data_raw_all = pd.read_csv(\"bank.csv\", header=0, sep=\";\")\n",
    "\n",
    "data_raw_all = pd.read_csv(body, header=0, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(num_rows, num_cols) : (4521, 17)\n",
      "attributes : ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y']\n",
      "\n",
      "\n",
      "'Bank data set preview'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education default  balance housing loan  \\\n",
       "0   30   unemployed  married    primary      no     1787      no   no   \n",
       "1   33     services  married  secondary      no     4789     yes  yes   \n",
       "2   35   management   single   tertiary      no     1350     yes   no   \n",
       "3   30   management  married   tertiary      no     1476     yes  yes   \n",
       "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  cellular   19   oct        79         1     -1         0  unknown  no  \n",
       "1  cellular   11   may       220         1    339         4  failure  no  \n",
       "2  cellular   16   apr       185         1    330         1  failure  no  \n",
       "3   unknown    3   jun       199         4     -1         0  unknown  no  \n",
       "4   unknown    5   may       226         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview \n",
    "print(\"(num_rows, num_cols) :\", data_raw_all.shape)\n",
    "print(\"attributes :\", list(data_raw_all.columns))\n",
    "\n",
    "print (\"\\n\\n'Bank data set preview'\")\n",
    "data_raw_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set schema\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "job          object\n",
       "marital      object\n",
       "education    object\n",
       "default      object\n",
       "balance       int64\n",
       "housing      object\n",
       "loan         object\n",
       "contact      object\n",
       "day           int64\n",
       "month        object\n",
       "duration      int64\n",
       "campaign      int64\n",
       "pdays         int64\n",
       "previous      int64\n",
       "poutcome     object\n",
       "y            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# schema\n",
    "print(\"Data set schema\")\n",
    "data_raw_all.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration using Seaborn and Matplotlib\n",
    "\n",
    "Lets start with data exploration. As we explore, we hope to \n",
    "\n",
    "* Look at big picture.\n",
    "* Get insights into the data and problem. \n",
    "* If possible, redefine the problem statement based.\n",
    "\n",
    "\n",
    "Usually, for exploratory analysis, one samples input dataset. However, our dataset is small and hence\n",
    "we will put the sample fraction to be 1.0. For the bigger dataset, one may want to change fraction accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "## cleaning routines\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "     Clean the data for the exploratory analysis\n",
    "     \n",
    "     arguements:\n",
    "     df -- pandas dataframe.\n",
    "     \n",
    "    \"\"\"\n",
    "    # drop the missing data row\n",
    "    data = df.dropna()\n",
    "    \n",
    "    # first convert the day type to object - Since day is not of int64 type but a categorical type\n",
    "    data['day'] = df.astype('object')\n",
    "\n",
    "   \n",
    "    return data\n",
    "\n",
    "# \n",
    "data_ex = clean_data(data_raw_all) #.sample(frac=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Explore output\n",
    "\n",
    "\n",
    "##### Positive and Negative Class Distribution.\n",
    "\n",
    "We know the output i.e client response 'y' can be 'yes' or 'no'. Lets see it's relative frequencies.\n",
    "Since we are interested in predicting when client is going to purchase a term deposit, out positive sample is 'yes' and\n",
    "negative samples is 'no'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ibm/conda/miniconda3/lib/python3.5/site-packages/seaborn/categorical.py:1460: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f20d1120e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='y', data=data_ex, palette='husl')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "We can see that we have class imbalances between positive and negative classes (positive samples are around 10% and negative samples are around 90%). The class imbalance is very common in the real dataset. We will see that this imabalance causes problem in our model performance. However there are a lot of ways to mitigate it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Check if there is the class skew wrt other numerical columns\n",
    "\n",
    "Lets see for the numeric column, on average if there is a pattern in the two classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>40.998000</td>\n",
       "      <td>1403.211750</td>\n",
       "      <td>226.347500</td>\n",
       "      <td>2.862250</td>\n",
       "      <td>36.006000</td>\n",
       "      <td>0.471250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>42.491363</td>\n",
       "      <td>1571.955854</td>\n",
       "      <td>552.742802</td>\n",
       "      <td>2.266795</td>\n",
       "      <td>68.639155</td>\n",
       "      <td>1.090211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      balance    duration  campaign      pdays  previous\n",
       "y                                                                     \n",
       "no   40.998000  1403.211750  226.347500  2.862250  36.006000  0.471250\n",
       "yes  42.491363  1571.955854  552.742802  2.266795  68.639155  1.090211"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean of the numeric features and how it effects output\n",
    "\n",
    "data_ex.groupby('y').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We note that:\n",
    "\n",
    "   *  age, balance, day, compaign are balanced between 'yes' and 'no' classes and hence probably not the best predictors\n",
    "   *  duration feature as explained in the dataset shouldn't be used for prediction and we will not analyse this feature\n",
    "   *  pdays feature indicates that usually the conversion happens if the client are contacted not frequently\n",
    "   *  previous feature indicates that more the number of times client are contacted more likely he will be a positive sample.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Explore the inputs\n",
    "\n",
    "We can get many insights into the data set by exploring the inputs i.e features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Distribution and corelation of the numeric columns\n",
    "\n",
    "Lets plot the distribution of the features and their cross co-relation to get the information about reduntant features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ibm/conda/miniconda3/lib/python3.5/site-packages/matplotlib/contour.py:967: UserWarning: The following kwargs were not used by contour: 'marker', 'color', 'label'\n",
      "  s)\n",
      "/opt/ibm/conda/miniconda3/lib/python3.5/site-packages/statsmodels/nonparametric/kernels.py:128: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return (1. / np.sqrt(2 * np.pi)) * np.exp(-(Xi - x)**2 / (h**2 * 2.))\n",
      "/opt/ibm/conda/miniconda3/lib/python3.5/site-packages/statsmodels/nonparametric/kernels.py:128: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (1. / np.sqrt(2 * np.pi)) * np.exp(-(Xi - x)**2 / (h**2 * 2.))\n",
      "/opt/ibm/conda/miniconda3/lib/python3.5/site-packages/statsmodels/nonparametric/_kernel_base.py:514: RuntimeWarning: invalid value encountered in true_divide\n",
      "  dens = Kval.prod(axis=1) / np.prod(bw[iscontinuous])\n",
      "/opt/ibm/conda/miniconda3/lib/python3.5/site-packages/matplotlib/contour.py:1533: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/opt/ibm/conda/miniconda3/lib/python3.5/site-packages/matplotlib/contour.py:1534: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n",
      "/opt/ibm/conda/miniconda3/lib/python3.5/site-packages/matplotlib/contour.py:1176: RuntimeWarning: invalid value encountered in greater\n",
      "  inside = (self.levels > self.zmin) & (self.levels < self.zmax)\n",
      "/opt/ibm/conda/miniconda3/lib/python3.5/site-packages/matplotlib/contour.py:1176: RuntimeWarning: invalid value encountered in less\n",
      "  inside = (self.levels > self.zmin) & (self.levels < self.zmax)\n",
      "/opt/ibm/conda/miniconda3/lib/python3.5/site-packages/matplotlib/contour.py:1180: UserWarning: No contour levels were found within the data range.\n",
      "  warnings.warn(\"No contour levels were found\"\n"
     ]
    }
   ],
   "source": [
    "# create the scatter plot.\n",
    "num_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "num_cols_with_y = num_cols + ['y']\n",
    "\n",
    "g = sns.pairplot(data_ex[num_cols_with_y], \n",
    "                 hue = 'y',  # yes is green and \n",
    "                 diag_kind='hist',  # histogram plot for diag\n",
    "                 dropna=True,\n",
    "                 markers=[',', ','], # markers for yes and no                 \n",
    "                 palette=sns.color_palette(['red', 'green']), # # yes is green and no is red\n",
    "                 plot_kws={\n",
    "                     's':3 # size of the point\n",
    "                 },\n",
    "                 \n",
    "                )\n",
    "g = g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the following insights\n",
    "\n",
    "* All the columns of interests (i.e diagonal plot) has the predictive power (as none of them are uniform). \n",
    "\n",
    "* The class imbalance is high (i.e green color 'yes' is far less than red colored 'no' in the diag plot)\n",
    "\n",
    "* Non diagonal lower matrix plot contains contour plot for pairwise features.\n",
    "\n",
    "* Non diagonal upper matrix plot contains the corelation between pairwise corelation. For example cell (1 rst row, 3rd column) shows that there is some corelation between 'age' and 'days' feature. So to get the better feel, we will plot the heat map co-relation matrix also.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the corelation between inputs\n",
    "corr = data_ex[num_cols].corr()\n",
    "\n",
    "# plot heatmap\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values, yticklabels=corr.columns.values,\n",
    "            cmap=sns.light_palette(\"navy\"),\n",
    "           )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that:\n",
    "\n",
    "* pdays and previous features are correlated heavily and we should use one of them\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did various exploratory analysis to get more insights into the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Test and Train Set.\n",
    "\n",
    "Now it is time to split aside the train and test dataset. Why is it that we makes this decision at this stage?\n",
    "Since if we don't do it and train our model on the whole dataset and then test it on the part of the dataset, we are testing on the subset of data which was used for training and hence we will never know whether our model generalizes well or not.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To split the dataset into training and testing, we will use scikit learn's utility [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). It works also with pandas dataframe and we don't have to do any conversion from pandas to numpy data type.\n",
    "\n",
    "For Model Training, we will sub-split train set and only in the end, we will use test set for generalization test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "d = defaultdict(LabelEncoder)\n",
    "\n",
    "# Encoding the variable\n",
    "data_ex_label = data_ex.apply(lambda x: d[x.name].fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data_ex_label.loc [:, data_ex_label.columns !='y']\n",
    "y= data_ex_label.loc [:, data_ex_label.columns =='y']\n",
    "    \n",
    "#70% training dataset\n",
    "seed=10\n",
    "test_size=0.3\n",
    "X_train,X_test,y_train,y_test = train_test_split (X,y,test_size=test_size,random_state=seed)\n",
    "    \n",
    "print('Size of Training Dataset: ',X_train.shape,y_train.shape)\n",
    "print('Size of Testing Dataset: ',X_test.shape,y_test.shape)\n",
    "print('Test data propotion', test_size*100, '%')\n",
    "print(\"Sample of the training dataset \\n\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the decision tree classifier. \n",
    "clf = DecisionTreeClassifier(criterion = 'entropy')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =  clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test['y'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for Model Performance <a name=\"metrics_perf\"></a>\n",
    "\n",
    "To come up with the best model, we should evaluate model performance for comparison amongs models.There are many ways to evaluate the model performance for classification.\n",
    "\n",
    "1) Accuracy Score\n",
    "\n",
    "2) Confusion Matrix\n",
    "\n",
    "3) ROC curve\n",
    "\n",
    "4) Precision Recall Curve\n",
    "\n",
    "We will discuss and create utilities for the above in next few sections\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Accuracy Score\n",
    "Accuracy is just the ratio of the number of correctly classified samples to the total number of samples.\n",
    "This is very simple score but it in case of the class imbalance, the score can be misleading. Hence, we \n",
    "will not use this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "count_misclassified = (y_test != y_pred).sum()\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Confusion Matrix\n",
    "\n",
    "Apart from the accuracy, the following performance measures for the models are also very helpful to measure it's performance on test dataset.\n",
    "\n",
    "* The number of samples correctly predicted as negative i.e True Negative (TN).\n",
    "\n",
    "* The number of samples correctly predicted as positive i.e True Positive (TP). These are also used in accuracy calculation.\n",
    "\n",
    "* The number of samples which were positive but were predicted as negative i.e False Negative (FN).\n",
    "\n",
    "* The number of samples which were negative but were predicted as positive i.e False Positive (FP).\n",
    "\n",
    "[Confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) gives above mentioned metrics of performance and is widely used for classification task.\n",
    "\n",
    "We have created a utility to visualize confusion matrix based on the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix: ') \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Report : ')\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages and Disadvantages of Trees\n",
    "*Following are the advantages of decision trees:*\n",
    "- Easy to use and understand. \n",
    "- Can handle both categorical and numerical data. \n",
    "- Resistant to outliers, hence require little data preprocessing. \n",
    "- New features can be easily added. \n",
    "- Can be used to build larger classifiers by using ensemble methods.\n",
    "\n",
    "*Following are the disadvantages of decision trees:* \n",
    "- Prone to overfitting. \n",
    "- Require some kind of measurement as to how well they are doing. \n",
    "- Need to be careful with parameter tuning. \n",
    "- Can create biased learned trees if some classes dominate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy For Better Classifier for the Imbalance Data <a name=\"ml_clf_strategy\"></a>\n",
    "\n",
    "Can we do better than the current performance? The answer is yes and typically in these cases, we follow the following \n",
    "techniques.\n",
    "\n",
    "1) Use the weighted class i.e give higher weight for the class 1 i.e 'yes'\n",
    "\n",
    "2) OverSampling of the Minority class and Undersampling of the minority class\n",
    "\n",
    "3) Use the SMOTE (synthetic Minority class oversampling)\n",
    "   \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
